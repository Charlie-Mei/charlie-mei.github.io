[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Charlie Mei",
    "section": "",
    "text": "Welcome to my website!\nI am a data professional who understands how to make strategic recommendations through data.\nCurrently, I work in FinTech, but have experience working in Management Consulting and MarTech."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Charlie Mei",
    "section": "Education",
    "text": "Education\nColumbia University | New York City, US | Master of Science\nUniversity of Melbourne | Melbourne, AU | Bachelor of Commerce (Hons)"
  },
  {
    "objectID": "projects/predicting_airbnb.html",
    "href": "projects/predicting_airbnb.html",
    "title": "Predicting Airbnb Prices",
    "section": "",
    "text": "The rise of Airbnb has provided travelers with an alluring, alternate method of accommodation. Instead of staying in traditional hotels, eager travelers now have the option of staying in other people’s homes, making for more of a personal living experience. While we have since seen a meteoric rise in the number of Airbnb stays, hosts of Airbnb accommodations face the dilemma of setting optimal prices for charging travelers for their stay.\nThis project provides an exploration of different machine learning models in order to understand how best to predict Airbnb prices. This project was based on a dataset consisting of 90 features related to the property, the host and the reviews of over 35,000 rental properties.\n\n\nThere are many factors to take into consideration when identifying the best model for predicting Airbnb prices.\nIf we are purely looking for a model with the highest level of accuracy, then this becomes a simple statistical problem - identifying the model the performs best against some predefined evaluation metric. As is often the case, however, the best performing models are often statistically complex and difficult to interpret. Machine learning models are often great at identifying unique patterns within the data, however those patterns are often difficult to comprehend due to the complex math behind its calculations.\nIf instead the purpose was to create a customizable machine learning tool that Airbnb hosts could use to price accommodations based on the unique features of their own accommodations, having a more easily interpretable model could be more beneficial to promote usage.\nSince this project focused on the exploration of various machine learning tools, the best price model was based purely from a statistical point of view. Therefore, the best price model was the one that yielded the lowest root mean squared error (RMSE).\n\n\n\nThe following supervised machine learning models were tested as part of this project:\n\nlinear regression\npenalized linear regression (ridge and lasso)\nrandom forest.\n\n\n\n\nEfforts were made to ensure that any additional features coming out of the original data were captured through feature engineering. Even though, it was found that linear regression models reached a level of RMSE that plateaued upon adding additional features into the model. This does make sense, as the more features that are added to such models, the higher likelihood of collinearity issues creeping in, giving rise to potential bias with the end modeling results. Additionally, penalized regression models will indeed place less emphasis on such correlated features, and so it is difficult to achieve any great leaps in RMSE using linear regression models.\nRandom forest modeling resulted in an RMSE that was around 2x lower than the linear regressions tested. Random forests use the advantage of, at its core, decision trees that divide the original data into useful subcategories. These subcategories are then selected at random based on which features reduce RMSE the most after repeatedly sampling the data a specified number of times. It appears that this approach performs better than simple linear regression models that enforce simple relationships between features and price."
  },
  {
    "objectID": "projects/predicting_airbnb.html#predicting-airbnb-prices",
    "href": "projects/predicting_airbnb.html#predicting-airbnb-prices",
    "title": "Predicting Airbnb Prices",
    "section": "",
    "text": "The rise of Airbnb has provided travelers with an alluring, alternate method of accommodation. Instead of staying in traditional hotels, eager travelers now have the option of staying in other people’s homes, making for more of a personal living experience. While we have since seen a meteoric rise in the number of Airbnb stays, hosts of Airbnb accommodations face the dilemma of setting optimal prices for charging travelers for their stay.\nThis project provides an exploration of different machine learning models in order to understand how best to predict Airbnb prices. This project was based on a dataset consisting of 90 features related to the property, the host and the reviews of over 35,000 rental properties.\n\n\nThere are many factors to take into consideration when identifying the best model for predicting Airbnb prices.\nIf we are purely looking for a model with the highest level of accuracy, then this becomes a simple statistical problem - identifying the model the performs best against some predefined evaluation metric. As is often the case, however, the best performing models are often statistically complex and difficult to interpret. Machine learning models are often great at identifying unique patterns within the data, however those patterns are often difficult to comprehend due to the complex math behind its calculations.\nIf instead the purpose was to create a customizable machine learning tool that Airbnb hosts could use to price accommodations based on the unique features of their own accommodations, having a more easily interpretable model could be more beneficial to promote usage.\nSince this project focused on the exploration of various machine learning tools, the best price model was based purely from a statistical point of view. Therefore, the best price model was the one that yielded the lowest root mean squared error (RMSE).\n\n\n\nThe following supervised machine learning models were tested as part of this project:\n\nlinear regression\npenalized linear regression (ridge and lasso)\nrandom forest.\n\n\n\n\nEfforts were made to ensure that any additional features coming out of the original data were captured through feature engineering. Even though, it was found that linear regression models reached a level of RMSE that plateaued upon adding additional features into the model. This does make sense, as the more features that are added to such models, the higher likelihood of collinearity issues creeping in, giving rise to potential bias with the end modeling results. Additionally, penalized regression models will indeed place less emphasis on such correlated features, and so it is difficult to achieve any great leaps in RMSE using linear regression models.\nRandom forest modeling resulted in an RMSE that was around 2x lower than the linear regressions tested. Random forests use the advantage of, at its core, decision trees that divide the original data into useful subcategories. These subcategories are then selected at random based on which features reduce RMSE the most after repeatedly sampling the data a specified number of times. It appears that this approach performs better than simple linear regression models that enforce simple relationships between features and price."
  },
  {
    "objectID": "projects/strategizing_customer_retention.html",
    "href": "projects/strategizing_customer_retention.html",
    "title": "Strategizing customer retention with customer review data",
    "section": "",
    "text": "As customer needs grow more and more complex, businesses require a deeper understanding of their customers in order to boost retention and brand loyalty. Anonymized product reviews provide a treasure grove of data for companies to better understand their customers.\nThis spring, I worked with a group of fellow classmates from grad school to understand how businesses can break down text data to understand their customers.\nWe found a dataset on reviews of women’s e-commerce clothing reviews on Kaggle. The dataset provided text data on how each customer reviewed and rated their purchase, as well as a flag that indicated whether or not they recommended their product of purhcase. The dataset was related to a specific, anonymized e-commerce retailer.\nFrom this data, it was possible to understand:\n\nthe overall sentiment for clothing items\nwhether there was a relationship between specific words/sentiment on whether they end up recommending the product to others.\n\n\n\nA wordcloud offers a quick exploratory way to understand the typical words used by reviewers of clothing products. It appears words such as “fit”, “size” and “look” are among the top five words used. This result is interesting; thee words potentially reveal the main factors that customers are considering as they are considering whether or not to buy a certain clothing product.\n\n\n\nTop 100 Words\n\n\nWe also assigned sentiment scores to the words used by reviewers. Our method of score allocation was based on the “Afinn” lexicon, as that method anks words used by customers on a scale of -5 to 5, where the higher the number indicates the more positive the sentiment. Based on this approach, it appears that customers tended to have, on average, a positive sentiment on the clothing products offered by this retailer.\n\n\n\nSentiment\n\n\n\n\n\nAfter constructing a vocabulary of words, we proceeded to use a random forest model to understand whether the words used in customer reviews and/or their sentiment can reveal likelihood of recommendation.\nRandom forest models are particularly useful in extracting the top explanatory factors for a given outcome. In this case, whether or not the product was recommended was the target outcome, with the frequency count of words used by customers being the explanatory factors. As each decision tree is run, only a small random subset of words will be used to predict recommendation. After being repeated multiple times, the most important words are revealed as those that reduce the error in correctly classifying recommendaiton by the largest amounts.\nA variable importance plot visualizes the results from this analysis. The numeric axis indicates by how much each word/sentiment reduces the error in predicting recommendatio. Based on this approach, we identified consumer sentiment as the key predictor for recommending the product. In terms of words, “class”, “return”, “age” and “perfect” were all top predictors of recommendation too.\n\n\n\nModeling Results\n\n\n\n\n\nThe results from our analysis indicate that there is indeed value for businesses in using customer review data to understand their customers. While surveys and focus groups are traditional approaches, basic text analysis also offers a complementary tool to deriving new and potentially surprising strategies for reducing customer churn and increasing customer loyalty."
  },
  {
    "objectID": "projects/strategizing_customer_retention.html#strategizing-customer-retention-with-customer-review-data",
    "href": "projects/strategizing_customer_retention.html#strategizing-customer-retention-with-customer-review-data",
    "title": "Strategizing customer retention with customer review data",
    "section": "",
    "text": "As customer needs grow more and more complex, businesses require a deeper understanding of their customers in order to boost retention and brand loyalty. Anonymized product reviews provide a treasure grove of data for companies to better understand their customers.\nThis spring, I worked with a group of fellow classmates from grad school to understand how businesses can break down text data to understand their customers.\nWe found a dataset on reviews of women’s e-commerce clothing reviews on Kaggle. The dataset provided text data on how each customer reviewed and rated their purchase, as well as a flag that indicated whether or not they recommended their product of purhcase. The dataset was related to a specific, anonymized e-commerce retailer.\nFrom this data, it was possible to understand:\n\nthe overall sentiment for clothing items\nwhether there was a relationship between specific words/sentiment on whether they end up recommending the product to others.\n\n\n\nA wordcloud offers a quick exploratory way to understand the typical words used by reviewers of clothing products. It appears words such as “fit”, “size” and “look” are among the top five words used. This result is interesting; thee words potentially reveal the main factors that customers are considering as they are considering whether or not to buy a certain clothing product.\n\n\n\nTop 100 Words\n\n\nWe also assigned sentiment scores to the words used by reviewers. Our method of score allocation was based on the “Afinn” lexicon, as that method anks words used by customers on a scale of -5 to 5, where the higher the number indicates the more positive the sentiment. Based on this approach, it appears that customers tended to have, on average, a positive sentiment on the clothing products offered by this retailer.\n\n\n\nSentiment\n\n\n\n\n\nAfter constructing a vocabulary of words, we proceeded to use a random forest model to understand whether the words used in customer reviews and/or their sentiment can reveal likelihood of recommendation.\nRandom forest models are particularly useful in extracting the top explanatory factors for a given outcome. In this case, whether or not the product was recommended was the target outcome, with the frequency count of words used by customers being the explanatory factors. As each decision tree is run, only a small random subset of words will be used to predict recommendation. After being repeated multiple times, the most important words are revealed as those that reduce the error in correctly classifying recommendaiton by the largest amounts.\nA variable importance plot visualizes the results from this analysis. The numeric axis indicates by how much each word/sentiment reduces the error in predicting recommendatio. Based on this approach, we identified consumer sentiment as the key predictor for recommending the product. In terms of words, “class”, “return”, “age” and “perfect” were all top predictors of recommendation too.\n\n\n\nModeling Results\n\n\n\n\n\nThe results from our analysis indicate that there is indeed value for businesses in using customer review data to understand their customers. While surveys and focus groups are traditional approaches, basic text analysis also offers a complementary tool to deriving new and potentially surprising strategies for reducing customer churn and increasing customer loyalty."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "A collection of data-related projects to solve real world problems\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting Airbnb Prices\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nSentiment tracking during COVID-19\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nStrategizing customer retention with customer review data\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2020\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/sentiment_tracking.html",
    "href": "projects/sentiment_tracking.html",
    "title": "Sentiment tracking during COVID-19",
    "section": "",
    "text": "The airline industry was severely impacted by the COVID-19 pandemic. Being able to track consumer sentiment towards the airline industry can help airlines understand when we may be turning the corner and ready for a bounceback.\nA copy of the report can be found here."
  },
  {
    "objectID": "projects/sentiment_tracking.html#sentiment-tracking-during-covid-19",
    "href": "projects/sentiment_tracking.html#sentiment-tracking-during-covid-19",
    "title": "Sentiment tracking during COVID-19",
    "section": "",
    "text": "The airline industry was severely impacted by the COVID-19 pandemic. Being able to track consumer sentiment towards the airline industry can help airlines understand when we may be turning the corner and ready for a bounceback.\nA copy of the report can be found here."
  }
]